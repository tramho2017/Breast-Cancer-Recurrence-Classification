table(y)
data<-read.csv("C:/Users/tramh/iCloudDrive/Documents/MA 5790 Predictive Statistic/Project/Project 2/breast-cancer-data.csv")
data
dim(data)
# Creating dummy Variables
simple<-dummyVars(class~age+menopause+tumer.size+inv.nodes+node.caps+deg.malig+breast+breast.quad+irradiate,data=data)
data1<-predict(simple,data)
dim(data1) #286  43
str(data1)
data$class
unique(data$class)
y<-c()
y[which(data$class=="recurrence-events'") ]=1
y[which(data$class=="no-recurrence-events'") ]=0
y
table(y)
# Barplots of categorical predictors
a<-colnames(data1)
data1[,1]
dim(data1)
# for (i in 1:10){
# plot(data1[,i],y, ylab="churn")
# }
# plot(data1[,1:10],y, ylab="churn")
# data1[,1:10]
names<-colnames(data1)
dim(data1)# 286  43
plot.new()
# Barplots of categorical predictors
a<-colnames(data1)
data1[,1]
dim(data1)
# for (i in 1:10){
# plot(data1[,i],y, ylab="churn")
# }
# plot(data1[,1:10],y, ylab="churn")
# data1[,1:10]
names<-colnames(data1)
dim(data1)# 286  43
#plot.new()
par(mfrow=c(5,4))
for (i in 1:20){
counts<-table(data1[,i])
pl<-barplot(counts,main=names[i])
}
# Barplots of categorical predictors
a<-colnames(data1)
data1[,1]
dim(data1)
# for (i in 1:10){
# plot(data1[,i],y, ylab="churn")
# }
# plot(data1[,1:10],y, ylab="churn")
# data1[,1:10]
names<-colnames(data1)
dim(data1)# 286  43
##plot.new()
par(mfrow=c(5,4))
for (i in 1:20){
counts<-table(data1[,i])
pl<-barplot(counts,main=names[i])
}
# Barplots of categorical predictors
a<-colnames(data1)
data1[,1]
dim(data1)
# for (i in 1:10){
# plot(data1[,i],y, ylab="churn")
# }
# plot(data1[,1:10],y, ylab="churn")
# data1[,1:10]
names<-colnames(data1)
dim(data1)# 286  43
##plot.new()
par(mfrow=c(5,4))
for (i in 1:20){
counts<-table(data1[,i])
pl<-barplot(counts,main=names[i])
}
# Barplots of categorical predictors
a<-colnames(data1)
data1[,1]
dim(data1)
# for (i in 1:10){
# plot(data1[,i],y, ylab="churn")
# }
# plot(data1[,1:10],y, ylab="churn")
# data1[,1:10]
names<-colnames(data1)
dim(data1)# 286  43
##plot.new()
par(mfrow=c(5,4))
for (i in 1:20){
counts<-table(data1[,i])
pl<-barplot(counts,main=names[i])
}
##plot.new()
par(mfrow=c(6,4))
for (i in 21:43){
counts<-table(data1[,i])
pl<-barplot(counts,main=names[i])
}
# Barplot of response
##plot.new()
tableY<-table(y)
barplot(tableY, main="The Distribution of Response Variable")
heatmap(cor(data1), main="Heatmap of Variable Correlations \n before Transformation")
apply(data1,2 ,skewness)
n<-nearZeroVar(data1,freqCut=95/5)
length(n)
data2<-data1[,-n]
str(data2)
dim(data2)
trans1<-kNN(data2,imp_var=FALSE)
str(trans1)
corre<-cor(trans1)
heatmap(corre, main="Heatmap of Variable  Correlations")
t<-findCorrelation(corre,cutoff=0.8)
length(t)
data3<-trans1[,-t]
apply(data3,2 ,skewness)
trans<-preProcess(data3,method=c("BoxCox","center","scale"))
data4<-predict(trans,data3)
apply(data4,2 ,skewness)
data5<-spatialSign(data4)
apply(data5,2 ,skewness)
apply(data5,2 ,skewness)
dim(data5) # 286  26
str(data5)
heatmap(cor(data5), main="Heatmap of Correlations \n after Transformation")
y1<-c()
y1[which(y==0)]<-"Class1"
y1[which(y==1)]<-"Class2"
unique(y1)
y2<-factor(y1,labels=c('Class1','Class2'))
set.seed(123)
index<-createDataPartition(y,p=0.8,list=FALSE)
length(index)
trainX<-data5[index,]
dim(trainX)
trainY<-y2[index]
testX<-data5[-index,]
testY<-y2[-index]
length(trainY) #229
length(testY) # 57
dim(trainX) #229  26
dim(testX) #57 26
str(trainY)
library(caret)
set.seed(1)
ctrl <- trainControl(method = "LGOCV",
summaryFunction = twoClassSummary,
classProbs = TRUE,
##index = list(simulatedTest[,1:4]),
savePredictions = TRUE)
set.seed(123)
lModel <- train(trainX,
y = trainY,
method = "glm",
metric = "ROC",
# preProc=c("center","scale","pca")
trControl = ctrl)
#plot(lModel)
# predict on training set
#Predict on the training set
LoPred<-predict(lModel, trainX)
postResample(pred=LoPred,obs=trainY)
confusionMatrix(lModel$pred$pred,lModel$pred$obs)
LPredProbs<-predict(lModel, newdata=trainX,type="prob")
LFullRoc<-multiclass.roc(response=trainY, predictor=LPredProbs)
auc(LFullRoc)# 0.8149
plot(lModel# 0.8149
plot(lModel)# 0.8149
plot(lModel)# 0.8149
plot(LDATrain)# 0.8149
ctrl <- trainControl(method = "LGOCV",summaryFunction =twoClassSummary,classProbs = TRUE,savePredictions = TRUE)
LDATrain <- train(x=trainX,trainY,method = "lda", metric = "auc", trControl = ctrl)
#Predict on the training set
LPred<-predict(LDATrain, trainX)
postResample(pred=LPred,obs=trainY)
confusionMatrix(LDATrain$pred$pred,LDATrain$pred$obs)
#confusionMatrix(LPred,trainY)
LPredProbs<-predict(LDATrain, newdata=trainX,type="prob")
FullRoc<-multiclass.roc(response=trainY, predictor=LPredProbs)
auc(FullRoc)
plot(LDATrain)# 0.8149
#ctrl <- trainControl(method = "LGOCV",summaryFunction =twoClassSummary,classProbs = TRUE,savePredictions = TRUE)
ctrl <- trainControl(method = "LGOCV",
summaryFunction =multiClassSummary,
classProbs = TRUE,
##index = list(simulatedTest[,1:4]),
# preprocess("")
savePredictions = TRUE)
LDATrain <- train(x=trainX,trainY,method = "lda", metric = "auc", trControl = ctrl)
#Predict on the training set
LPred<-predict(LDATrain, trainX)
postResample(pred=LPred,obs=trainY)
confusionMatrix(LDATrain$pred$pred,LDATrain$pred$obs)
#confusionMatrix(LPred,trainY)
LPredProbs<-predict(LDATrain, newdata=trainX,type="prob")
FullRoc<-multiclass.roc(response=trainY, predictor=LPredProbs)
auc(FullRoc)
plot(LDATrain)# 0.8149
library(caret)
set.seed(1)
dim(trainX)
ctrl <- trainControl(method = "LGOCV",summaryFunction =twoClassSummary,classProbs = TRUE,savePredictions = TRUE)
plsModel <- train(x = trainX,
y = trainY,
method = "pls",
tuneGrid = expand.grid(.ncomp = 1:26),
preProc = c("center","scale"),
metric = "auc",
trControl = ctrl)
plsModel
plot.new()
par(mfrow=c(1,1))
plot(plsModel,main="Area Under the Curve Per Additional Component with PLSDA Model")
# predict on training set
pred<-predict(plsModel,trainX)
confusionMatrix(plsModel$pred$pred,plsModel$pred$obs)
confusionMatrix(pred,trainY)
predYes<-predict(PLS,trainX,type="prob")
plsPredProbs<-predict(plsModel, newdata=trainX,type="prob")
plsRoc<-multiclass.roc(response=trainY, predictor=plsPredProbs)
auc(plsRoc) # 0.8067
plot(plsModel,main="ROC of  PLSDA Model")
library(caret)
set.seed(1)
ctrl <- trainControl(method = "LGOCV",
summaryFunction = twoClassSummary,
classProbs = TRUE,
##index = list(simulatedTest[,1:4]),
savePredictions = TRUE)
set.seed(123)
lModel <- train(trainX,
y = trainY,
method = "glm",
metric = "ROC",
# preProc=c("center","scale","pca")
trControl = ctrl)
#plot(lModel)
# predict on training set
#Predict on the training set
LoPred<-predict(lModel, trainX)
postResample(pred=LoPred,obs=trainY)
confusionMatrix(lModel$pred$pred,lModel$pred$obs)
LPredProbs<-predict(lModel, newdata=trainX,type="prob")
LFullRoc<-multiclass.roc(response=trainY, predictor=LPredProbs)
auc(LFullRoc)
plot(lModel)# 0.8149
library(caret)
set.seed(1)
ctrl <- trainControl(method = "LGOCV",
summaryFunction = twoClassSummary,
classProbs = TRUE,
##index = list(simulatedTest[,1:4]),
savePredictions = TRUE)
set.seed(123)
lModel <- train(trainX,
y = trainY,
method = "glm",
metric = "auc",
# preProc=c("center","scale","pca")
trControl = ctrl)
#plot(lModel)
# predict on training set
#Predict on the training set
LoPred<-predict(lModel, trainX)
postResample(pred=LoPred,obs=trainY)
confusionMatrix(lModel$pred$pred,lModel$pred$obs)
LPredProbs<-predict(lModel, newdata=trainX,type="prob")
LFullRoc<-multiclass.roc(response=trainY, predictor=LPredProbs)
auc(LFullRoc)
plot(lModel)# 0.8149
LPredProbs<-predict(lModel, newdata=trainX,type="prob")
LFullRoc<-multiclass.roc(response=trainY, predictor=LPredProbs)
auc(LFullRoc)
plot(lModel)# 0.8149
auc(LFullRoc)
library(caret)
set.seed(1)
ctrl <- trainControl(method = "LGOCV",
summaryFunction = defaultSummary,
classProbs = TRUE,
##index = list(simulatedTest[,1:4]),
savePredictions = TRUE)
set.seed(123)
lModel <- train(trainX,
y = trainY,
method = "glm",
metric = "auc",
# preProc=c("center","scale","pca")
trControl = ctrl)
#plot(lModel)
# predict on training set
#Predict on the training set
LoPred<-predict(lModel, trainX)
postResample(pred=LoPred,obs=trainY)
confusionMatrix(lModel$pred$pred,lModel$pred$obs)
LPredProbs<-predict(lModel, newdata=trainX,type="prob")
LFullRoc<-multiclass.roc(response=trainY, predictor=LPredProbs)
auc(LFullRoc)
plot(lModel)# 0.8149
library(caret)
set.seed(1)
ctrl <- trainControl(method = "LGOCV",
summaryFunction = twoclassSummary,
classProbs = TRUE,
##index = list(simulatedTest[,1:4]),
savePredictions = TRUE)
library(caret)
set.seed(1)
ctrl <- trainControl(method = "LGOCV",
summaryFunction = twoClassSummary,
classProbs = TRUE,
##index = list(simulatedTest[,1:4]),
savePredictions = TRUE)
set.seed(123)
lModel <- train(trainX,
y = trainY,
method = "glm",
metric = "auc",
# preProc=c("center","scale","pca")
trControl = ctrl)
#plot(lModel)
# predict on training set
#Predict on the training set
LoPred<-predict(lModel, trainX)
postResample(pred=LoPred,obs=trainY)
confusionMatrix(lModel$pred$pred,lModel$pred$obs)
LPredProbs<-predict(lModel, newdata=trainX,type="prob")
LFullRoc<-multiclass.roc(response=trainY, predictor=LPredProbs)
auc(LFullRoc)
plot(lModel)# 0.8149
library(caret)
library(pROC)
ctrl <- trainControl(method = "LGOCV",
summaryFunction = twoClassSummary,
classProbs = TRUE,
##index = list(simulatedTest[,1:4]),
savePredictions = TRUE)
glGrid <- expand.grid(.alpha = c(0, .1, .2, .4, .6, .8, 1),
.lambda = seq(.01, .2, length = 40))
set.seed(476)
glTune<- train(x=trainX,
y = trainY,
method = "glmnet",
tuneGrid = glGrid,
preProc = c("center", "scale"),
metric = "auc",
trControl = ctrl)
glTune
plot(glTune)
glTune$results$Accuracy
plot(glTune,main="Tuning Parameters of Logistic Model")
#Predict on the training set:
gPred<-predict(glTune, trainX)
postResample(pred=gPred,obs=trainY)
confusionMatrix(glTune$pred$pred,glTune$pred$obs)
confusionMatrix(gPred,trainY)
gPredProbs<-predict(glTune, newdata=trainX,type="prob")
gRoc<-multiclass.roc(response=trainY, predictor=gPredProbs)
auc(gRoc)#0.804
#Predict on the test set:
glPred<-predict(glTune, testX)
postResample(pred=glPred,obs=testY)
confusionMatrix(glPred,testY)
glPredProbs<-predict(glTune, newdata=testX,type="prob")
glRoc<-multiclass.roc(response=testY, predictor=glPredProbs)
auc(glRoc)#0.5726
ctrl <- trainControl(summaryFunction = twoClassSummary,
classProbs = TRUE)
sigma <- sigest(as.matrix(trainX))
svmRGrid <- expand.grid(.sigma = sigma[1],
.C = 2^(seq(-2, 7)))
svmModel <- train(x = trainX,
y = trainY,
method = "svmRadial",
metric = "auc",
preProc = c("center", "scale"),
tuneGrid = svmRGrid,
fit = FALSE,
trControl = ctrl)
svmModel
summary(svmModel)
plot(svmModel, main=" Tuning Parameters of\n Support Vector Machine Model ")
#Predict on the training set:
sPred <- predict(svmModel, newdata = trainX,type="raw")
confusionMatrix(data = sPred,reference =trainY)
sPredProbs<-predict(svmModel, newdata=trainX,type="prob")
sRoc<-multiclass.roc(response=trainY, predictor=sPredProbs)
auc(sRoc) #0.819
#Predict on the test set:
svmPred <- predict(svmModel, newdata = testX,type="raw")
confusionMatrix(data = svmPred,reference =testY)
svmPredProbs<-predict(svmModel, newdata=testX,type="prob")
svmRoc<-multiclass.roc(response=testY, predictor=svmPredProbs)
auc(svmRoc) #0.7151
varImp(svmModel)
marsGrid <- expand.grid(.degree = 1:2, .nprune = 2:30)
fdaTuned <- train(x = trainX,
y = trainY,
method = "fda",
preProcess = c("center", "scale"),
# Explicitly declare the candidate models to test
tuneGrid = marsGrid,
trControl = trainControl(method = "cv"))
warnings()
fdaTuned
plot(fdaTuned, main="Tuning Parameters of \n Flexible Discriminant Analysis Model ")
#Predict on the training set:
fPred <- predict(fdaTuned, newdata = trainX,type="raw")
#confusionMatrix(fdaTuned$pred$pred,fdaTuned$pred$obs)
confusionMatrix(data = fPred,reference =trainY)
fPredProbs<-predict(fdaTuned, newdata=trainX,type="prob")
fRoc<-multiclass.roc(response=trainY, predictor=fPredProbs)
auc(fRoc) #   0.7755
fdaPred <- predict(fdaTuned, newdata = testX,type="raw")
confusionMatrix(data = fdaPred,reference =testY)
fdaPredProbs<-predict(fdaTuned, newdata=testX,type="prob")
fdaRoc<-multiclass.roc(response=testY, predictor=fdaPredProbs)
auc(fdaRoc) #
plot(glTune)
plot(glTune,main="Tuning Parameters of Penalized Model")
confusionMatrix(glTune$pred$pred,glTune$pred$obs)
library(caret)
library(pROC)
ctrl <- trainControl(method = "LGOCV",
summaryFunction = twoClassSummary,
classProbs = TRUE,
##index = list(simulatedTest[,1:4]),
savePredictions = TRUE)
glGrid <- expand.grid(.alpha = c(0, .1, .2, .4, .6, .8, 1),
.lambda = seq(.01, .2, length = 40))
set.seed(476)
glTune<- train(x=trainX,
y = trainY,
method = "glmnet",
tuneGrid = glGrid,
preProc = c("center", "scale"),
metric = "auc",
trControl = ctrl)
glTune
plot(glTune,main="Tuning Parameters of Penalized Model")
glTune$results$Accuracy
plot(glTune,main="Tuning Parameters of Penalized Model")
#Predict on the training set:
gPred<-predict(glTune, trainX)
postResample(pred=gPred,obs=trainY)
confusionMatrix(glTune$pred$pred,glTune$pred$obs)
gPredProbs<-predict(glTune, newdata=trainX,type="prob")
gRoc<-multiclass.roc(response=testY, predictor=gPredProbs)
gRoc<-multiclass.roc(response=trainY, predictor=gPredProbs)
auc(gRoc)#0.5726
auc(plsRoc) # 0.8067
library(caret)
set.seed(1)
ctrl <- trainControl(method = "LGOCV",
summaryFunction = twoClassSummary,
classProbs = TRUE,
##index = list(simulatedTest[,1:4]),
savePredictions = TRUE)
lModel <- train(trainX,
y = trainY,
method = "glm",
metric = "auc",
# preProc=c("center","scale","pca")
trControl = ctrl)
#Predict on the training set
LPred<-predict(lModel, trainX)
postResample(pred=LPred,obs=trainY)
confusionMatrix(lModel$pred$pred,lModel$pred$obs)
LPredProbs<-predict(lModel, newdata=trainX,type="prob")
LFullRoc<-multiclass.roc(response=trainY, predictor=LPredProbs)
auc(LFullRoc)# 0.8149
plot(glTune,main="Tuning Parameters of Penalized Model")
ctrl <- trainControl(method = "LGOCV",
summaryFunction = twoClassSummary,
classProbs = TRUE,
##index = list(simulatedTest[,1:4]),
savePredictions = TRUE)
glGrid <- expand.grid(.alpha = c(0, .1, .2, .4, .6, .8, 1),
.lambda = seq(.01, .2, length = 40))
set.seed(476)
glTune<- train(x=trainX,
y = trainY,
method = "glmnet",
tuneGrid = glGrid,
preProc = c("center", "scale"),
metric = "auc",
trControl = ctrl)
glTune
plot(glTune,main="Tuning Parameters of Penalized Model")
#Predict on the training set:
gPred<-predict(glTune, trainX)
postResample(pred=gPred,obs=trainY)
confusionMatrix(glTune$pred$pred,glTune$pred$obs)
gPredProbs<-predict(glTune, newdata=trainX,type="prob")
gRoc<-multiclass.roc(response=trainY, predictor=gPredProbs)
auc(gRoc)
plot(glTune,main="Tuning Parameters of Penalized Model")
plot(glTune,main="Tuning Parameters of Penalized Model")
confusionMatrix(data = svmPred,reference =testY)
auc(svmRoc) #0.7151
confusionMatrix(data = svmPred,reference =testY)
auc(svmRoc) #0.7151
confusionMatrix(nbPred,testY)
auc(nbRoc) #
confusionMatrix(nbPred,testY)
auc(svmRoc) #0.7151
confusionMatrix(data = svmPred,reference =testY)
